{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Importing/Storing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wfdb \n",
    "\n",
    "### Python waveform-database (WFDB) package. Library of tools for reading, writing, and processing WFDB signals and annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below cell is running a seperate script in here first. The script contains NSRDB variables.\n",
    "### This is nessecary to obtain variables that are needed for evaluation purposes in (7) Results section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount to remove -11\n",
      "Shape 0: 30113\n",
      "Features for that specific segment:\n",
      "Mean                160.400\n",
      "STD                   8.830\n",
      "RMSSD                 0.338\n",
      "Normalized RMSSD      0.002\n",
      "dtype: float64\n",
      "\n",
      "features2 variable contains 30113 segments\n",
      "float64\n",
      "Length of y_list: 30113\n"
     ]
    }
   ],
   "source": [
    "%run \"MIT-BIH Normal Sinus Rhythm DB.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "properties = []\n",
    "annot = []\n",
    "AnnSymb = []\n",
    "AnnSamp = []\n",
    "AnnRhythm = []\n",
    "Rpeak_Samp = []\n",
    "Rpeak_Symb = []\n",
    "\n",
    "\n",
    "for f in glob.glob('C:/Users/masud/Skrivebord/Github_Bachelor_Project/wfdb-python/data/atrial_fibrillation_data/*.dat'): ##### change the path to own directory.       \n",
    "                                                                                             ##### The rest should remin the same\n",
    "                                                                                             ##### Useful function:\n",
    "                                                                                             ##### print('Current directory is: {}'.format(os.getcwd()))\n",
    "    sig, fields = wfdb.rdsamp(f[:-4], channels=[1])  #### In this function, pass \n",
    "                                                     #### \"channels=[0]\" or \"channels=[1]\" to select channel 1 or 2.\n",
    "    ann = wfdb.rdann(f[:-4], 'atr')\n",
    "    QRS = wfdb.rdann(f[:-4], 'qrs')\n",
    "    Symb = pd.Series(ann.symbol)\n",
    "    Samp = pd.Series(ann.sample)\n",
    "    QRS_Symb = pd.Series(QRS.symbol)\n",
    "    QRS_Samp = pd.Series(QRS.sample)\n",
    "    Rhythm = pd.Series(ann.aux_note)\n",
    "    records.append(sig)\n",
    "    properties.append(fields)\n",
    "    annot.append(ann)\n",
    "    AnnSymb.append(Symb)\n",
    "    AnnSamp.append(Samp)\n",
    "    Rpeak_Symb.append(QRS_Symb)\n",
    "    Rpeak_Samp.append(QRS_Samp)\n",
    "    AnnRhythm.append(Rhythm)\n",
    "    \n",
    "    \n",
    "\n",
    "AnnSymb = pd.Series(AnnSymb).values\n",
    "AnnSamp = pd.Series(AnnSamp).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Checking the content of some variables (for the last record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AnnSamp[22]) ### This specific record contains 4 changes of cardiac states, they are outputted in following cell (\"AnnRhythm[]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       (N\n",
       "1    (AFIB\n",
       "2       (N\n",
       "3    (AFIB\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnnRhythm[22] ### The 4 changes in the last record (starting normal rythm, than atrial fib rythm, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         96\n",
       "1    2808396\n",
       "2    2820743\n",
       "3    2850351\n",
       "dtype: int32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnnSamp[22] ### Specific sample points the changes occur, 96 to 2808396 is (N and from 2808396 to 2820743 is (AFIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            193\n",
       "1            390\n",
       "2            586\n",
       "3            782\n",
       "4            905\n",
       "          ...   \n",
       "59547    8999654\n",
       "59548    8999811\n",
       "59549    8999879\n",
       "59550    8999948\n",
       "59551    9000001\n",
       "Length: 59552, dtype: int32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rpeak_Samp[22] ### Output sample points that contains the R-peak of the given record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Pre processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Rpeaks amount: 1128561\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for i in range(23):\n",
    "    x += np.sum(len(Rpeak_Samp[i]))\n",
    "print(f\"All Rpeaks amount: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labeled_Rpeaks = []\n",
    "appended_data = []\n",
    "for i in range(23): ## 23 records\n",
    "    for j in range(len(AnnSamp[i])-1): ## AnnSamp or AnnRhythm -- both same dimensions\n",
    "        df = pd.DataFrame(Rpeak_Samp[i][(Rpeak_Samp[i] > AnnSamp[i][j]) & (Rpeak_Samp[i] < AnnSamp[i][j+1])])\n",
    "        df['Label'] = AnnRhythm[i][j]\n",
    "        appended_data.append(df)\n",
    "        \n",
    "\n",
    "labeled_Rpeaks = pd.concat(appended_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering, only get hearbeats with annotations '(N' OR '(AFIB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>(N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>(N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>358</td>\n",
       "      <td>(N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>584</td>\n",
       "      <td>(N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>729</td>\n",
       "      <td>(N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>149897</td>\n",
       "      <td>(AFIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>149989</td>\n",
       "      <td>(AFIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>150086</td>\n",
       "      <td>(AFIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>150169</td>\n",
       "      <td>(AFIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>150248</td>\n",
       "      <td>(AFIB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  Label\n",
       "0        61     (N\n",
       "1       200     (N\n",
       "2       358     (N\n",
       "3       584     (N\n",
       "4       729     (N\n",
       "..      ...    ...\n",
       "995  149897  (AFIB\n",
       "996  149989  (AFIB\n",
       "997  150086  (AFIB\n",
       "998  150169  (AFIB\n",
       "999  150248  (AFIB\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_Rpeaks_N_AFIB = labeled_Rpeaks.loc[(labeled_Rpeaks.Label == '(N') | (labeled_Rpeaks.Label == '(AFIB'), :]\n",
    "#labeled_Rpeaks_N_AFIB\n",
    "labeled_Rpeaks_N_AFIB[0:1000] ### Outputting the first 1000 instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "         ... \n",
       "15373    True\n",
       "15374    True\n",
       "15375    True\n",
       "15376    True\n",
       "15377    True\n",
       "Name: Label, Length: 708567, dtype: bool"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_to_keep = ['(N', '(AFIB']\n",
    "labeled_Rpeaks_N_AFIB['Label'].isin(values_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_result = labeled_Rpeaks_N_AFIB['Label'].isin(values_to_keep)\n",
    "[i for i in bool_result if i is False] ### If list is empty, no unwanted values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert 'Label' column to boolean expr ----> '(AFIB' = 1 and '(N' = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-10b1fee2832c>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labeled_Rpeaks_N_AFIB['Label'] = labeled_Rpeaks_N_AFIB['Label'].map(\n"
     ]
    }
   ],
   "source": [
    "labeled_Rpeaks_N_AFIB['Label'] = labeled_Rpeaks_N_AFIB['Label'].map( \n",
    "                   {'(N':False ,'(AFIB':True}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-9cd7ad84a37a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labeled_Rpeaks_N_AFIB['Label'] = labeled_Rpeaks_N_AFIB['Label'].astype(int)\n",
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:4441: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "labeled_Rpeaks_N_AFIB['Label'] = labeled_Rpeaks_N_AFIB['Label'].astype(int)\n",
    "\n",
    "labeled_Rpeaks_N_AFIB.rename(columns={0: 'Rpeaks'},\n",
    "          inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rpeaks_N_AFIB = labeled_Rpeaks_N_AFIB[\"Rpeaks\"]\n",
    "Label_N_AFIB = labeled_Rpeaks_N_AFIB[\"Label\"]\n",
    "Label_N_AFIB = np.array(Label_N_AFIB, dtype=np.float64)\n",
    "\n",
    "labeled_Rpeaks_N_AFIB.isnull().values.any() ### Check for NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Segmenting & Feature Calculating "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X - section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def segmenting_record(seg_value):\n",
    "    rri2 = np.diff(Rpeaks_N_AFIB) ### Storing the intervals between rpeaks\n",
    "    rri2 = np.array(rri2, dtype=np.float64) ### Ensuring no overflow issues happens, when calculating in for loop later\n",
    "\n",
    "    amount = -(len(rri2) % seg_value) # amount of data points to remove, for equal length segments with no residue points\n",
    "    print(f\"Amount to remove {amount}\")\n",
    "    \n",
    "    rec_amount = rri2[:amount]\n",
    "    seg_shape = len(rec_amount) // seg_value # amount of total segments (given the specified segment length) \n",
    "    print(f\"Shape 0: {seg_shape}\")\n",
    "    \n",
    "    segmented_rec = rec_amount.reshape(seg_shape,seg_value) \n",
    "    return segmented_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Following function (above) is used, when different segment lengths is preffered (inputtet below)\n",
    "### 2. Then read the outputs \"Amount to remove\" and \"Shape 0\" copy and paste this in the \"Y - section\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount to remove -26\n",
      "Shape 0: 11809\n"
     ]
    }
   ],
   "source": [
    "segmented_record = segmenting_record(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segmented_record[137]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loads in functions for Shannon Entropy, Mean absolute deviation and Median absolute deiviation calculations\n",
    "%run \"features_utils.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = []\n",
    "\n",
    "### Calculating features for every single segmented \"block\" inside the segmented_record variable\n",
    "for x in range(len(segmented_record)):\n",
    "    \n",
    "    #MEAN\n",
    "    ff1 = np.nanmean(segmented_record[x]) ### nanmean, nanstd computes values while ignoring nan-values\n",
    "    #STD\n",
    "    ff2 = np.nanstd(segmented_record[x])\n",
    "    #RMSSD\n",
    "    sum_ = 0\n",
    "    for y in range(len(segmented_record[x]) - 1): ### loops 19 times\n",
    "        sum_ += (segmented_record[x][y] - segmented_record[x][y+1])**2\n",
    "    sum_multiplied = 1/(len(segmented_record) - 1) * sum_\n",
    "    ff3 = np.sqrt(sum_multiplied)\n",
    "    #NORMALIZED RMSSD\n",
    "    ff4 = (ff3 / ff1)\n",
    "    #SHANNON ENTROPY\n",
    "    ff5 = entropy(segmented_record[x])\n",
    "    #MEAN ABSOLUTE DEVIATION\n",
    "    ff6 = mean_abs_deviation(segmented_record[x])\n",
    "    #MEDIAN ABSOLUTE DEVIATION\n",
    "    ff7 = median_abs_deviation(segmented_record[x])\n",
    "    \n",
    "    #COVARIANCE\n",
    "    #z = np.stack((ff1, ff2))\n",
    "    #ff5 = np.cov(z) ### try cov with previous segment\n",
    "\n",
    "    my_features2 = pd.Series([np.around(ff1,3), np.around(ff2,3), np.around(ff3,3), np.around(ff4,3), np.around(ff5,3), \n",
    "                             np.around(ff6,3), np.around(ff7,3)],\n",
    "                            index=['Mean','STD','RMSSD','Normalized RMSSD','Shannon Entropy',\n",
    "                                   'Mean absolute deviation','Median absolute deiviation'])\n",
    "    features2.append(my_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features calculated for an example segment:\n",
      "Mean                          162.700\n",
      "STD                            53.453\n",
      "RMSSD                           4.102\n",
      "Normalized RMSSD                0.025\n",
      "Shannon Entropy                 0.934\n",
      "Mean absolute deviation        46.930\n",
      "Median absolute deiviation     43.500\n",
      "dtype: float64\n",
      "\n",
      "features2 variable contains 11809 segments\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "print(f\"Features calculated for an example segment:\\n{features2[n]}\") \n",
    "print('\\n'f\"features2 variable contains {len(features2)} segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y - section "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paste the copied information below (indicated with the arrows)\n",
    "1. Arrow: Add \"Amount to remove\" - 1, (remember the negative sign).\n",
    "2. Arrow: Add \"Shape 0\" as first argument and the segment size as second argument. (Shape 0 , segment size)\n",
    "3. Arrow: Divide segment size by 2 and add here. (meaning, if over half the segment contains \"(AFIB\", than classify the whole segment as \"(AFIB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "Length of y_list: 11809\n"
     ]
    }
   ],
   "source": [
    "y_amount = Label_N_AFIB[:-27] # <=============== (1)\n",
    "y_shape = y_amount.reshape(11809, 60) # <=============== (2)\n",
    "y_list = []\n",
    "\n",
    "### Calc if every 20 segment block is Normal synus rythm or AFIB\n",
    "for l in range(len(y_shape)):\n",
    "    #y_segment = y_shape\n",
    "    sum_segment = np.sum(y_shape[l])\n",
    "    if sum_segment >= 30: # <=============== (3)\n",
    "        sum_segment = 1\n",
    "    else: sum_segment = 0\n",
    "    y_list.append(sum_segment)\n",
    "\n",
    "y_list = np.array(y_list, dtype=np.float64)\n",
    "print(y_list.dtype)\n",
    "print(f\"Length of y_list: {len(y_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (below) Print shapes, to check if the segments allign for y and X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y: (11809,), type of y: <class 'numpy.ndarray'>\n",
      "shape of X: (11809, 7), type of X: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y = np.asarray(y_list)\n",
    "print(f\"shape of y: {np.shape(y)}, type of y: {type(y)}\")\n",
    "X = np.asarray(features2)\n",
    "print(f\"shape of X: {np.shape(X)}, type of X: {type(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (below) Print shapes, to check if the segments allign for y_nsr and X_nsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_nsr = np.asarray(y_list_nsr)\n",
    "print(f\"shape of y: {np.shape(y_nsr)}, type of y: {type(y_nsr)}\")\n",
    "X_nsr = np.asarray(features2_nsr)\n",
    "print(f\"shape of X: {np.shape(X_nsr)}, type of X: {type(X_nsr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Choosen params after runned GridsearchCV \n",
    "\n",
    "pipeline_svm = Pipeline([('scalar1', StandardScaler()),\n",
    "                         ('svm_classifier', SVC(gamma=\"scale\", C=20, kernel='rbf', probability=True))])\n",
    "\n",
    "pipeline_dt = Pipeline([('scalar2', StandardScaler()),\n",
    "                        ('dt_classifier', tree.DecisionTreeClassifier(criterion='entropy', max_depth=12))])\n",
    "\n",
    "pipeline_rf = Pipeline([('scalar 4', StandardScaler()),\n",
    "                         ('rf_classifier', RandomForestClassifier(n_estimators=200))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nsr, X_test_nsr, y_train_nsr, y_test_nsr = train_test_split(X_nsr, y_nsr, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('svm',pipeline_svm), ('dt',pipeline_dt), ('rf',pipeline_rf)]\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression(), stack_method='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaBoost_clf = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6) Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold ### For class inbalances through out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring = ['test_score'] # for test scores\n",
    "# scoring = ['precision_macro'] # alternative scoring example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time # approx 1 hour to run for segment length = 20\n",
    "cv_svm_results = cross_validate(pipeline_svm, X, y, cv=5,\n",
    "                        return_estimator=False, return_train_score=True) ### set return_estimator=True to return the fitted estimator\n",
    "\n",
    "cv_dt_results = cross_validate(pipeline_dt, X, y, cv=5,\n",
    "                        return_estimator=False, return_train_score=True)\n",
    "\n",
    "cv_rf_results = cross_validate(pipeline_rf, X, y, cv=5,\n",
    "                        return_estimator=False, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# approx half hour to run for segment length = 20\n",
    "cv_stacking_results = cross_validate(clf, X, y, cv=5,\n",
    "                        return_estimator=False, return_train_score=True)\n",
    "cv_xgb_results = cross_validate(xgb_model, X, y, cv=5,\n",
    "                        return_estimator=False, return_train_score=True)\n",
    "cv_ab_results = cross_validate(adaBoost_clf, X, y, cv=5,\n",
    "                        return_estimator=False, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (7) Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7.1) Feature results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>STD</th>\n",
       "      <th>RMSSD</th>\n",
       "      <th>Normalized RMSSD</th>\n",
       "      <th>Shannon Entropy</th>\n",
       "      <th>Mean absolute deviation</th>\n",
       "      <th>Median absolute deiviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162.700</td>\n",
       "      <td>53.453</td>\n",
       "      <td>4.102</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.934</td>\n",
       "      <td>46.930</td>\n",
       "      <td>43.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>178.033</td>\n",
       "      <td>42.349</td>\n",
       "      <td>3.831</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.922</td>\n",
       "      <td>39.130</td>\n",
       "      <td>44.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163.517</td>\n",
       "      <td>55.033</td>\n",
       "      <td>4.397</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.911</td>\n",
       "      <td>47.472</td>\n",
       "      <td>31.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169.967</td>\n",
       "      <td>55.567</td>\n",
       "      <td>5.061</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.903</td>\n",
       "      <td>48.057</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141.267</td>\n",
       "      <td>52.538</td>\n",
       "      <td>3.788</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.932</td>\n",
       "      <td>39.216</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11804</th>\n",
       "      <td>186.983</td>\n",
       "      <td>13.098</td>\n",
       "      <td>1.610</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.512</td>\n",
       "      <td>3.821</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11805</th>\n",
       "      <td>150.533</td>\n",
       "      <td>49.275</td>\n",
       "      <td>4.481</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.909</td>\n",
       "      <td>42.518</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11806</th>\n",
       "      <td>145.933</td>\n",
       "      <td>50.787</td>\n",
       "      <td>4.117</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.867</td>\n",
       "      <td>44.013</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11807</th>\n",
       "      <td>190.017</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.552</td>\n",
       "      <td>2.020</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11808</th>\n",
       "      <td>188.217</td>\n",
       "      <td>2.026</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.493</td>\n",
       "      <td>1.627</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11809 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean     STD  RMSSD  Normalized RMSSD  Shannon Entropy  \\\n",
       "0      162.700  53.453  4.102             0.025            0.934   \n",
       "1      178.033  42.349  3.831             0.022            0.922   \n",
       "2      163.517  55.033  4.397             0.027            0.911   \n",
       "3      169.967  55.567  5.061             0.030            0.903   \n",
       "4      141.267  52.538  3.788             0.027            0.932   \n",
       "...        ...     ...    ...               ...              ...   \n",
       "11804  186.983  13.098  1.610             0.009            0.512   \n",
       "11805  150.533  49.275  4.481             0.030            0.909   \n",
       "11806  145.933  50.787  4.117             0.028            0.867   \n",
       "11807  190.017   2.500  0.154             0.001            0.552   \n",
       "11808  188.217   2.026  0.159             0.001            0.493   \n",
       "\n",
       "       Mean absolute deviation  Median absolute deiviation  \n",
       "0                       46.930                        43.5  \n",
       "1                       39.130                        44.5  \n",
       "2                       47.472                        31.5  \n",
       "3                       48.057                        24.5  \n",
       "4                       39.216                        19.0  \n",
       "...                        ...                         ...  \n",
       "11804                    3.821                         1.0  \n",
       "11805                   42.518                        42.0  \n",
       "11806                   44.013                        16.5  \n",
       "11807                    2.020                         2.0  \n",
       "11808                    1.627                         1.5  \n",
       "\n",
       "[11809 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.DataFrame(features2)\n",
    "X = df5.values\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5.to_excel(\"features.xlsx\")\n",
    "#print(\"min is\", df5.Mean.min())\n",
    "#print(\"max is\", df5.Mean.max())\n",
    "#print(\"range is\", df5.Mean.max()-df5.Mean.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot = df5.boxplot(column=['Mean']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(1235)\n",
    "# df = pd.DataFrame(np.random.randn(10, 4),\n",
    "#                   columns=['Col1', 'Col2', 'Col3', 'Col4'])\n",
    "# boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7.2) Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"SVM Scores: {cv_svm_results['test_score']}\")\n",
    "print(f\"Mean: {np.mean(cv_svm_results['test_score'])}\")\n",
    "print()\n",
    "print(f\"Decision tree Scores: {cv_dt_results['test_score']}\")\n",
    "print(f\"Mean: {np.mean(cv_dt_results['test_score'])}\")\n",
    "print()\n",
    "print(f\"Random forest: {cv_rf_results['test_score']}\")\n",
    "print(f\"Mean: {np.mean(cv_rf_results['test_score'])}\")\n",
    "print()\n",
    "print(f\"Stacking classifier Scores: {cv_stacking_results['test_score']}\")\n",
    "print(f\"Mean: {np.mean(cv_stacking_results['test_score'])}\")\n",
    "print()\n",
    "print(f\"xgboost Scores: {cv_xgb_results['test_score']}\")\n",
    "print(f\"Mean: {np.mean(cv_xgb_results['test_score'])}\")\n",
    "print()\n",
    "print(f\"AdaBoost Scores: {cv_ab_results['test_score']}\")\n",
    "print(f\"Mean: {np.mean(cv_ab_results['test_score'])}\")\n",
    "print(\"-------------------------------(Testing scores above)------------------------------------------------------\")\n",
    "print(\"-----------------------------------------------------------------------------------------------------------\")\n",
    "print(\"-------------------------------(Training scores below)-----------------------------------------------------\")\n",
    "print(f\"SVM Scores: {cv_svm_results['train_score']}\")\n",
    "print(f\"Mean: {np.mean(cv_svm_results['train_score'])}\")\n",
    "print()\n",
    "print(f\"Decision tree Scores: {cv_dt_results['train_score']}\")\n",
    "print(f\"Mean: {np.mean(cv_dt_results['train_score'])}\")\n",
    "print()\n",
    "print(f\"Random forest: {cv_rf_results['train_score']}\")\n",
    "print(f\"Mean: {np.mean(cv_rf_results['train_score'])}\")\n",
    "print()\n",
    "print(f\"Stacking classifier Scores: {cv_stacking_results['train_score']}\")\n",
    "print(f\"Mean: {np.mean(cv_stacking_results['train_score'])}\")\n",
    "print()\n",
    "print(f\"xgboost Scores: {cv_xgb_results['train_score']}\")\n",
    "print(f\"Mean: {np.mean(cv_xgb_results['train_score'])}\")\n",
    "print()\n",
    "print(f\"AdaBoost Scores: {cv_ab_results['train_score']}\")\n",
    "print(f\"Mean: {np.mean(cv_ab_results['train_score'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on MIT-BIH Normal Sinus Rhythm Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svm.fit(X_train, y_train)\n",
    "pipeline_dt.fit(X_train, y_train)\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "adaBoost_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"SVM: {pipeline_svm.score(X_test_nsr, y_test_nsr)}\")\n",
    "print(f\"DT: {pipeline_dt.score(X_test_nsr, y_test_nsr)}\")\n",
    "print(f\"RF: {pipeline_rf.score(X_test_nsr, y_test_nsr)}\")\n",
    "print()\n",
    "print(f\"Stacking: {clf.score(X_test_nsr, y_test_nsr)}\")\n",
    "print(f\"Xgbost: {xgb_model.score(X_test_nsr, y_test_nsr)}\")\n",
    "print(f\"AdaBoost: {adaBoost_clf.score(X_test_nsr, y_test_nsr)}\")\n",
    "print(\"------------------------------------(Testing scores above)----------------------------------------------------\")\n",
    "print(\"--------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"------------------------------------(Training scores below)---------------------------------------------------\")\n",
    "print(f\"SVM: {pipeline_svm.score(X_train_nsr, y_train_nsr)}\")\n",
    "print(f\"DT: {pipeline_dt.score(X_train_nsr, y_train_nsr)}\")\n",
    "print(f\"RF: {pipeline_rf.score(X_train_nsr, y_train_nsr)}\")\n",
    "print()\n",
    "print(f\"Stacking: {clf.score(X_train_nsr, y_train_nsr)}\")\n",
    "print(f\"Xgbost: {xgb_model.score(X_train_nsr, y_train_nsr)}\")\n",
    "print(f\"AdaBoost: {adaBoost_clf.score(X_train_nsr, y_train_nsr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7.3) Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = pipeline_svm.predict(X_test)\n",
    "y_pred_dt = pipeline_dt.predict(X_test)\n",
    "y_pred_rf = pipeline_rf.predict(X_test)\n",
    "y_pred_stacking = clf.predict(X_test)\n",
    "y_pred_xgboost = xgb_model.predict(X_test)\n",
    "y_pred_adaboost = adaBoost_clf.predict(X_test)\n",
    "\n",
    "\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "cm_stacking = confusion_matrix(y_test, y_pred_stacking)\n",
    "cm_xgboost = confusion_matrix(y_test, y_pred_xgboost)\n",
    "cm_adaboost = confusion_matrix(y_test, y_pred_adaboost)\n",
    "target_names = ['Normal', 'AFIB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (reminder) below cell is confusion matrices for nsr data (trained on afib data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_nsr = pipeline_svm.predict(X_test_nsr)\n",
    "y_pred_dt_nsr = pipeline_dt.predict(X_test_nsr)\n",
    "y_pred_rf_nsr = pipeline_rf.predict(X_test_nsr)\n",
    "y_pred_stacking_nsr = clf.predict(X_test_nsr)\n",
    "y_pred_xgboost_nsr = xgb_model.predict(X_test_nsr)\n",
    "y_pred_adaboost_nsr = adaBoost_clf.predict(X_test_nsr)\n",
    "\n",
    "\n",
    "cm_svm_nsr = confusion_matrix(y_test_nsr, y_pred_svm_nsr)\n",
    "cm_dt_nsr = confusion_matrix(y_test_nsr, y_pred_dt_nsr)\n",
    "cm_rf_nsr = confusion_matrix(y_test_nsr, y_pred_rf_nsr)\n",
    "cm_stacking_nsr = confusion_matrix(y_test_nsr, y_pred_stacking_nsr)\n",
    "cm_xgboost_nsr = confusion_matrix(y_test_nsr, y_pred_xgboost_nsr)\n",
    "cm_adaboost_nsr = confusion_matrix(y_test_nsr, y_pred_adaboost_nsr)\n",
    "target_names_nsr = ['Normal', 'AFIB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize = 20)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45, fontsize=15)\n",
    "        plt.yticks(tick_marks, target_names, fontsize=15)\n",
    "\n",
    "    if normalize:\n",
    "        cm = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]) * 100\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
    "                     fontsize=20, #####\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.2f}; misclass={:0.2f}'.format(accuracy, misclass), fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CM SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm_svm, target_names=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CM DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm_dt, target_names=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CM RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm_rf, target_names=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CM Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm_stacking, target_names=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CM XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm_xgboost, target_names=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CM AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm_adaboost, target_names=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CM SVM_NSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm_svm_nsr, target_names=target_names_nsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CM DT_NSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm_dt_nsr, target_names=target_names_nsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CM RF_NSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm_rf_nsr, target_names=target_names_nsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CM STACKING_NSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm_stacking_nsr, target_names=target_names_nsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CM XGBOOST_NSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm_xgboost_nsr, target_names=target_names_nsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CM ADABOOST_NSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm_adaboost_nsr, target_names=target_names_nsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability calculations for ROC and AUC metrics\n",
    "***(Do below code block only ONCE, do it before outputting/printing nsr results)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_svm = pipeline_svm.predict_proba(X_test)\n",
    "probs_dt = pipeline_dt.predict_proba(X_test)\n",
    "probs_rf = pipeline_rf.predict_proba(X_test)\n",
    "\n",
    "probs_stacking = pipeline_rf.predict_proba(X_test)\n",
    "probs_xgb = xgb_model.predict_proba(X_test)\n",
    "probs_ab = adaBoost_clf.predict_proba(X_test)\n",
    "\n",
    "\n",
    "### Probabilities for the positive outcome is kept\n",
    "probs_svm = probs_svm[:,1]\n",
    "probs_dt = probs_dt[:,1]\n",
    "probs_rf = probs_rf[:,1]\n",
    "\n",
    "probs_stacking = probs_stacking[:,1]\n",
    "probs_xgb = probs_xgb[:,1]\n",
    "probs_ab = probs_ab[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_svm = metrics.roc_auc_score(y_test, probs_svm)\n",
    "auc_dt = metrics.roc_auc_score(y_test, probs_dt)\n",
    "auc_rf = metrics.roc_auc_score(y_test, probs_rf)\n",
    "\n",
    "auc_stacking = metrics.roc_auc_score(y_test, probs_stacking)\n",
    "auc_xgb = metrics.roc_auc_score(y_test, probs_xgb)\n",
    "auc_ab = metrics.roc_auc_score(y_test, probs_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_swm, tpr_swm, thresholds_swm = metrics.roc_curve(y_test, probs_svm)\n",
    "fpr_dt, tpr_dt, thresholds_dt = metrics.roc_curve(y_test, probs_dt)\n",
    "fpr_rf, tpr_rf, thresholds_rf = metrics.roc_curve(y_test, probs_rf)\n",
    "\n",
    "fpr_stacking, tpr_stacking, thresholds_stacking = metrics.roc_curve(y_test, probs_stacking)\n",
    "fpr_xgb, tpr_xgb, thresholds_xgb = metrics.roc_curve(y_test, probs_xgb)\n",
    "fpr_ab, tpr_ab, thresholds_ab = metrics.roc_curve(y_test, probs_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7.4) ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0, 1], [0, 1], 'k--') # dashed line with black(k) color\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF (auc = %0.3f)' % auc_rf)\n",
    "plt.plot(fpr_swm, tpr_swm, label='SWM (auc = %0.3f)' % auc_svm)\n",
    "plt.plot(fpr_dt, tpr_dt, label='DT (auc = %0.3f)' % auc_dt)\n",
    "\n",
    "plt.plot(fpr_stacking, tpr_stacking, label='STACKING (auc = %0.3f)' % auc_stacking)\n",
    "plt.plot(fpr_xgb, tpr_xgb, label='XGB (auc = %0.3f)' % auc_xgb)\n",
    "plt.plot(fpr_ab, tpr_ab, label='AdaBoost (auc = %0.3f)' % auc_ab)\n",
    "\n",
    "plt.xlabel('False positive rate', fontsize=20)\n",
    "plt.ylabel('True positive rate', fontsize=20)\n",
    "plt.title('ROC curve', fontsize=20)\n",
    "plt.legend(loc='best', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0, 1], [0, 1], 'k--') # dashed line with black(k) color\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF (auc = %0.3f)' % auc_rf)\n",
    "plt.plot(fpr_swm, tpr_swm, label='SWM (auc = %0.3f)' % auc_svm)\n",
    "plt.plot(fpr_dt, tpr_dt, label='DT (auc = %0.3f)' % auc_dt)\n",
    "\n",
    "plt.xlabel('False positive rate', fontsize=20)\n",
    "plt.ylabel('True positive rate', fontsize=20)\n",
    "plt.title('ROC curve', fontsize=20)\n",
    "plt.legend(loc='best', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0, 1], [0, 1], 'k--') # dashed line with black(k) color\n",
    "\n",
    "plt.plot(fpr_stacking, tpr_stacking, label='STACKING (auc = %0.3f)' % auc_stacking)\n",
    "plt.plot(fpr_xgb, tpr_xgb, label='XGB (auc = %0.3f)' % auc_xgb)\n",
    "plt.plot(fpr_ab, tpr_ab, label='AdaBoost (auc = %0.3f)' % auc_ab)\n",
    "\n",
    "plt.xlabel('False positive rate', fontsize=20)\n",
    "plt.ylabel('True positive rate', fontsize=20)\n",
    "plt.title('ROC curve', fontsize=20)\n",
    "plt.legend(loc='best', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0, 1], [0, 1], 'k--') # dashed line with black(k) color\n",
    "\n",
    "plt.plot(fpr_stacking, tpr_stacking, marker='o', label='STACKING (auc = %0.3f)' % auc_stacking)\n",
    "\n",
    "plt.xlabel('False positive rate', fontsize=20)\n",
    "plt.ylabel('True positive rate', fontsize=20)\n",
    "plt.title('ROC curve', fontsize=20)\n",
    "plt.legend(loc='best', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0, 1], [0, 1], 'k--') # dashed line with black(k) color\n",
    "\n",
    "plt.plot(fpr_xgb, tpr_xgb, marker='o', label='XGB (auc = %0.3f)' % auc_xgb)\n",
    "\n",
    "plt.xlabel('False positive rate', fontsize=20)\n",
    "plt.ylabel('True positive rate', fontsize=20)\n",
    "plt.title('ROC curve', fontsize=20)\n",
    "plt.legend(loc='best', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0, 1], [0, 1], 'k--') # dashed line with black(k) color\n",
    "\n",
    "plt.plot(fpr_ab, tpr_ab, marker='o', label='AdaBoost (auc = %0.3f)' % auc_ab)\n",
    "\n",
    "plt.xlabel('False positive rate', fontsize=20)\n",
    "plt.ylabel('True positive rate', fontsize=20)\n",
    "plt.title('ROC curve', fontsize=20)\n",
    "plt.legend(loc='best', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7.5.1) Table overview: scoring = ['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment amount 10\n",
    "| Classifier | Scores | Mean Score |\n",
    "| :- | :- | :- |\n",
    "| SVM | [0.92075924 0.84080164 0.84313034 0.79733258 0.78378378] | 0.8371615163468551 |\n",
    "| Decision tree | [0.92075924 0.89704326 0.86662903 0.85794933 0.79225178] | 0.8669265294016855 |\n",
    "| Random forest | [0.92111205 0.89450286 0.87396796 0.86535883 0.79514501] | 0.8700173437011935 |\n",
    "| Stacking classifier | [0.92725092 0.89450286 0.8736857  0.8781314  0.79140498] | 0.8729951696998475 |\n",
    "|<b> <font color='blue'>xgboost</font> </b> | [0.92823878 0.90275916 0.87989556 0.86931056 0.79810881] | <b>0.875662575135407</b> |  \n",
    "| adaBoost | [0.93600056 0.91101545 0.8639475 0.86662903 0.78300755] | 0.8721200197506953 |\n",
    "| Voting Classifier (HARD) | No cross validation | 0.7318656505786058 |\n",
    "| Voting Classifier (SOFT) | No cross validation | 0.73652272085803 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment amount 15\n",
    "| Classifier | Scores | Mean Score |\n",
    "| :- | :- | :- |\n",
    "| SVM | [0.93056732 0.86515665 0.84767651 0.81475601 0.77379062] | 0.8463894204728962 |\n",
    "| Decision tree | [0.91712532 0.89997883 0.88557214 0.8959458  0.80067746] | 0.8798599109950456 |\n",
    "| Random forest | [0.91680779 0.89648603 0.88673653 0.89806288 0.806076  ] | 0.8808338457961511 |\n",
    "| Stacking classifier | [0.92876799 0.90008467 0.88663068 0.91923362 0.80205356] | 0.8873541049504132 |\n",
    "| <b> <font color='blue'>xgboost</font> </b> | [0.92749788 0.90643522 0.89266434 0.90462581 0.80872235] | <b>0.8879891196547574</b> |\n",
    "| adaBoost | [0.93681202 0.91151566 0.87339896 0.88800677 0.79919551] | 0.8817857874946883 |\n",
    "| Voting Classifier (HARD) | No cross validation | 0.8512559977420265 | \n",
    "| Voting Classifier (SOFT) | No cross validation | 0.857324301439458 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment amount 20\n",
    "| Classifier | Scores | Mean Score |\n",
    "| :- | :- | :- |\n",
    "| SVM | [0.9322608  0.87552921 0.86014677 0.86704305 0.76979534] | 0.8609550335419408 |\n",
    "| Decision tree | [0.92012419 0.9062941  0.88399661 0.89188426 0.79971771] | 0.8804033757261079 |\n",
    "| Random forest | [0.91913633 0.89627434 0.89867344 0.92025406 0.81425547] | 0.8897187273363582 |\n",
    "| Stacking classifier | [0.93000282 0.90093141 0.893593 0.92971066 0.8052223] | 0.8918920387512547 |\n",
    "| xgboost | [0.92238216 0.90220152 0.90333051 0.91743119 0.81580805] | 0.8922306869669157 |\n",
    "| adaBoost | [0.93353091 0.89895569 0.88583122 0.8962597  0.78645025] | 0.8802055520731189 |\n",
    "| Voting Classifier (HARD) | No cross validation | 0.9486311035845328 | \n",
    "| <b> <font color='blue'>Voting Classifier (SOFT)</font> </b> | No cross validation | <b>0.9508890770533446</b> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment amount 25\n",
    "| Classifier | Scores | Mean Score |\n",
    "| :- | :- | :- |\n",
    "| SVM | [0.93684953 0.88322455 0.87155963 0.87579393 0.77875794] | 0.8692371180632625 |\n",
    "| Decision tree | [0.90915505 0.90156994 0.8895554  0.9089626  0.81263232] | 0.8843750626324776 |\n",
    "| Random forest | [0.91920974 0.90174634 0.90561044 0.92589979 0.81986591]| 0.8944664447396997 |\n",
    "| Stacking classifier | [0.9310284  0.90421591 0.90137615 0.93772054 0.81351447] | 0.8975710922967126 |\n",
    "| <b> <font color='blue'>xgboost</font> </b> | [0.92432528 0.90245193 0.91037403 0.92978123 0.82127735] | <b>0.8976419626955051</b>|\n",
    "| adaBoost | [0.93543835 0.91585818 0.88143966 0.92043049 0.79569513]] | 0.8897723607436501 |\n",
    "| Voting Classifier (HARD) | No cross validation | 0.8755292125317528 | \n",
    "| Voting Classifier (SOFT) | No cross validation | 0.8760937058989556 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment amount 60\n",
    "| Classifier | Scores | Mean Score |\n",
    "| :- | :- | :- |\n",
    "| SVM | [0.9364945  0.89881456 0.87171888 0.90431837 0.80304956]| 0.8828791743907937 |\n",
    "| Decision tree | [0.91871296 0.92082981 0.9081287  0.92972058 0.82126218] | 0.8997308435374297 |\n",
    "| Random forest | [0.93183743 0.9322608  0.91447925 0.95004234 0.84709869] |  0.915143700142844 |\n",
    "| <b> <font color='blue'>Stacking classifier</font> </b> | [0.93776461 0.93141406 0.91320914 0.96062659 0.83566285] | <b>0.9157354498606878</b> |\n",
    "| xgboost | [0.92929721 0.92675699 0.9195597  0.95300593 0.84498094] | 0.9147201507993463 |\n",
    "| adaBoost | [0.93141406 0.92421677 0.8954276  0.93903472 0.81745023] | 0.9015086748715454 |\n",
    "| Voting Classifier (HARD) | No cross validation | 0.6841659610499576 |\n",
    "| Voting Classifier (SOFT) | No cross validation | 0.6881174146203782 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment amount 120\n",
    "| Classifier | Scores | Mean Score |\n",
    "| :- | :- | :- |\n",
    "| SVM | [0.93480102 0.91363251 0.86198137 0.94157494 0.79830508]| 0.8900589847730307 |\n",
    "| Decision tree | [0.90770533 0.92548688 0.88484335 0.94834886 0.82966102] | 0.8992090873864435 |\n",
    "| Random forest | [0.9237934  0.9407282  0.90685859 0.96104996 0.82457627] | 0.9114012830264497 |\n",
    "| <b> <font color='blue'>Stacking classifier</font> </b> | [0.93734124 0.9407282  0.89585097 0.96951736 0.81694915] | <b>0.9120773834297277</b> |\n",
    "| xgboost | [0.90855207 0.92887384 0.90347163 0.957663   0.83220339] | 0.9061527863488281 |\n",
    "| adaBoost | [0.93734124 0.9364945  0.88653683 0.95004234 0.81694915] | 0.9054728110334533 |\n",
    "| Voting Classifier (HARD) | No cross validation | 0.6699125035280835 |\n",
    "| Voting Classifier (SOFT) | No cross validation | 0.6783799040361276 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7.5.2) Table overview: scoring = ['precision_macro']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment amount 10\n",
    "\n",
    "| Classifier | Scores | Mean Score |\n",
    "| :- | :- | :- |\n",
    "| SVM | [0.90901609 0.82913128 0.83751363 0.79804735 0.79050442] | 0.8328425557402422 |\n",
    "| Decision tree | [0.9091379  0.883873   0.85304185 0.8529422  0.78019421] | 0.8558378305694516 |\n",
    "| Random forest | [0.91035706 0.88853696 0.85955471 0.85584218 0.78217434] | 0.859293050533927 |\n",
    "| Stacking classifier | [0.91633424 0.88794029 0.85991648 0.86799686 0.77727863] | 0.8618933018364766 |\n",
    "|<b> <font color='blue'>xgboost</font> </b> | [0.91781089 0.89484278 0.86629533 0.86209761 0.78692103] | <b>0.8655935272677568</b> |  \n",
    "| adaBoost | [0.92504207 0.90307636 0.85256869 0.86064788 0.77918339] | 0.8641036786319866 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment amount 20\n",
    "| Classifier | Scores | Mean Score |\n",
    "| :- | :- | :- |\n",
    "| SVM | [0.92118499 0.86178046 0.84719857 0.85588685 0.77298434] | 0.8518070430052868 |\n",
    "| Decision tree | [0.90463721 0.89701568 0.87030209 0.88093824 0.78244283] | 0.8670672086146567 |\n",
    "| Random forest | [0.90885777 0.89006886 0.88653765 0.90861018 0.80115661] | 0.8790462133976753 |\n",
    "| <b> <font color='blue'>Stacking classifier</font> </b> | [0.91872233 0.89636211 0.88322156 0.91809779 0.78941333] | <b>0.8811634252907714</b>|\n",
    "| xgboost | [0.91116523 0.89531492 0.89047711 0.90500501 0.80120198] | 0.8806328505197618 |\n",
    "| adaBoost | [0.92199619 0.89281512 0.87258715 0.88516904 0.77376375] | 0.8806328505197618 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment amount 60\n",
    "| Classifier | Scores | Mean Score |\n",
    "| :- | :- | :- |\n",
    "| SVM | [0.92501342 0.88580256 0.86103527 0.89190853 0.80146878]| 0.8730457106959557 |\n",
    "| Decision tree | [0.91315572 0.91338482 0.89238663 0.91800241 0.80481384] | 0.8883486859473735 |\n",
    "| Random forest | [0.91854214 0.92321429 0.90506758 0.93944582 0.83117845] |  0.9034896542288781 |\n",
    "| <b> <font color='blue'>Stacking classifier</font> </b> | [0.93226222 0.92338524 0.90520768 0.95202 0.82510008] | <b>0.9075950454507294</b> |\n",
    "| xgboost | [0.91850551 0.91925385 0.90759045 0.94505354 0.83007033] | 0.9040947345160714 |\n",
    "| adaBoost | [0.92001345 0.91576532 0.88294673 0.92885481 0.80175305] | 0.8898666720527755 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment amount 120\n",
    "| Classifier | Scores | Mean Score |\n",
    "| :- | :- | :- |\n",
    "| SVM | [0.92325695 0.90212192 0.85257555 0.93080192 0.7934675]| 0.880444768805296 |\n",
    "| Decision tree | [0.89160153 0.91648605 0.872511   0.94446946 0.81329853] | 0.8876733146580251 |\n",
    "| <b> <font color='blue'>Random forest</font> </b> | [0.91749582 0.93126885 0.89715865 0.96097628 0.8130069] |  <b>0.9039812993810619</b> |\n",
    "| Stacking classifier | [0.9283578  0.93419934 0.88484117 0.96806379 0.80084259] | 0.903260937296853 |\n",
    "| xgboost | [0.89934208 0.92393306 0.89098086 0.95323892 0.81823833] | 0.8971466500331117 |\n",
    "| adaBoost | [0.92644658 0.92807614 0.87398324 0.943755 0.80205616] | 0.894863424594331 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7.6.1) VotingClassifier (additional ensemble method results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('svm', pipeline_svm), ('dt', pipeline_dt), ('rf', pipeline_rf), \n",
    "        ('stacking', clf), ('xgb', xgb_model), ('AdaBoost', adaBoost_clf)], \n",
    "        voting='hard', verbose=1)\n",
    "eclf1 = eclf1.fit(X, y)\n",
    "\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[\n",
    "        ('svm', pipeline_svm), ('dt', pipeline_dt), ('rf', pipeline_rf), \n",
    "        ('stacking', clf), ('xgb', xgb_model), ('AdaBoost', adaBoost_clf)],\n",
    "        voting='soft', verbose=1)\n",
    "eclf2 = eclf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"---------TESTING----------\")\n",
    "print(eclf1.score(X_test, y_test))\n",
    "print(eclf2.score(X_test, y_test))\n",
    "print(\"---------TRAINING----------\")\n",
    "print(eclf1.score(X_train, y_train))\n",
    "print(eclf2.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7.6.2) CM Voting Classifier (Hard & Soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HARD\n",
    "y_pred_voting_clf_hard = eclf1.predict(X_test)\n",
    "cm_voting_clf_hard = confusion_matrix(y_test, y_pred_voting_clf_hard)\n",
    "### SOFT\n",
    "y_pred_voting_clf_soft = eclf2.predict(X_test)\n",
    "cm_voting_clf_soft = confusion_matrix(y_test, y_pred_voting_clf_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm_voting_clf_soft, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm_voting_clf_hard, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_voting_soft = eclf2.predict_proba(X_test)\n",
    "probs_voting_soft = probs_voting_soft[:,1]\n",
    "auc_voting_soft = metrics.roc_auc_score(y_test, probs_voting_soft)\n",
    "fpr_voting, tpr_voting, thresholds_voting = metrics.roc_curve(y_test, probs_voting_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0, 1], [0, 1], 'k--') # dashed line with black(k) color\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF (auc = %0.3f)' % auc_rf)\n",
    "plt.plot(fpr_swm, tpr_swm, label='SWM (auc = %0.3f)' % auc_svm)\n",
    "plt.plot(fpr_dt, tpr_dt, label='DT (auc = %0.3f)' % auc_dt)\n",
    "\n",
    "plt.plot(fpr_stacking, tpr_stacking, label='STACKING (auc = %0.3f)' % auc_stacking)\n",
    "plt.plot(fpr_xgb, tpr_xgb, label='XGB (auc = %0.3f)' % auc_xgb)\n",
    "plt.plot(fpr_ab, tpr_ab, label='AdaBoost (auc = %0.3f)' % auc_ab)\n",
    "\n",
    "plt.plot(fpr_voting, tpr_voting, label='Voting CLF \"SOFT\" (auc = %0.3f)' % auc_voting_soft)\n",
    "\n",
    "plt.xlabel('False positive rate', fontsize=20)\n",
    "plt.ylabel('True positive rate', fontsize=20)\n",
    "plt.title('ROC curve', fontsize=20)\n",
    "plt.legend(loc='best', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridsearchCV (all the possible combinations of parameter values are evaluated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "pipeline_svm.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from time import time\n",
    "# t0 = time()\n",
    "# parameters = {'svm_classifier__C':[1, 10, 20], 'svm_classifier__kernel':['linear', 'rbf']}\n",
    "# #parameters = {'rf_classifier__n_estimators': [200, 700], 'rf_classifier__max_features': ['auto', 'sqrt', 'log2'], 'rf_classifier__criterion':['gini','entropy']}\n",
    "# clf = GridSearchCV(pipeline_swm, parameters, cv=5)\n",
    "# clf.fit(X_train, y_train)\n",
    "# print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_search_results = pd.DataFrame(clf.cv_results_)\n",
    "#df_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df_search_results[['param_rf_classifier__criterion', 'param_rf_classifier__max_depth', 'mean_test_score']]\n",
    "#clf.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
